{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Y-a4g98w93GHswXLRLoiogvMYNPgzPE9","timestamp":1718115881996}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3DR-eO17geWu"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","source":["Convolution\n","<br>\n","fn: (f * g)(t) = integral from -inf to inf f(τ)g(t-τ)dτ\n","<br>\n","Input image + feature detector/kernel/filter (usuallu 3x3) -> convolution -> feature map by multiplying each small matrix (overlapping) in input image with filter (element * element) by moving through step (stride) -> convolved feature -> reduced size of image (high stride = smaller size)\n","<br>\n","Use diff filters -> multiple feature maps -> have lots of versions of the image -> model decides which to use where"],"metadata":{"id":"MTHy5vpSuV0O"}},{"cell_type":"markdown","source":["ReLU\n","applied on convolution layer -> increase non-linearity (images are non linear, necessary to break up linearity introduced by our process) -> turns all negatives to 0"],"metadata":{"id":"9zLikm_6x4PS"}},{"cell_type":"markdown","source":["Pooling/DownSampling\n","<br>\n","diff positions and orientations -> recognise feature -> spatial invariance -> identify feature even if its distorted\n","<br>\n","take a small part of feature map, take max value and put in pooled featur map -> move box by stride(1/2 pixels) -> feature preserved (max number = where input image and feature detector matched more), removing almost 75% of unwanted info, accounting for distortion by considering max value, reducing number of params, prevent overfitting\n","<br>\n","max pooling (taking max), mean/sum/sub-sampling"],"metadata":{"id":"eG6llDIpzUCH"}},{"cell_type":"markdown","source":["Flattening\n","<br>\n","pooled feature map -> flatten to column (row by row) -> input layer for ann"],"metadata":{"id":"m2wNt0QN1o94"}},{"cell_type":"markdown","source":["Full Connection\n","<br>\n","Adding ann to cnn, fully conn hidden layers, combine features into more attributes to predict the classes, output per class (no. of outputs not 1)\n","<br>\n","input image -> convolved, pooled, flattened -> go through ann -> prediction -> wrong pred -> error calc (loss function) -> back prop -> adjustments to optimise -> weights and feature detectors adjusted\n","<br>\n","Output neurons -> 2 classes = 2 outputs -> ans neuron gets activated, other ignores -> identify neurons that contribute to identifying features of that particular output -> give pred for each class"],"metadata":{"id":"XrtLyK5C18kV"}},{"cell_type":"markdown","source":["Softmax\n","<br>\n","Final prob add upto 1 -> since output neurons don't know the value of each other -> softmax fn -> out put of 2 neurons = z1 and z2 -> apply softmax fn (fj(z) = e^zj/sum of all k e^zk) -> normalised exponential fn -> squashes a k-dim vector of arbitrary values to a k-dim vector of real values bw 0 and 1 that add up to 1\n","<br>\n","<br>\n","Cross-Entropy\n","<br>\n","Li = -log(e^fyi/sum of all j e^fj)\n","<br>\n","H(p,q) = - sum of all x p(x)logq(x)\n","<br>\n","prob goes to q, 1/0 goes to p\n","<br>\n","Classification error = number of wrong pred/total number of pred\n","<br>\n","MSE = average of sum of squared errors\n","<br>\n","Cross Entropy = formula, helps assessing small errors (due to presence of log fn) since at the beginning, back-prop would not yield much due to small values"],"metadata":{"id":"oWOMqCux7Vxp"}},{"cell_type":"markdown","metadata":{"id":"EMefrVPCg-60"},"source":["### Importing the libraries"]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image"],"metadata":{"id":"PzqgNxOe-TY4","executionInfo":{"status":"ok","timestamp":1718372866682,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sanjala R","userId":"01601586496942134949"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oxQxCBWyoGPE"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"MvE-heJNo3GG"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","source":["# Image Augmentation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Feature scaling to each pixel\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","training_set = train_datagen.flow_from_directory(\n","    'dataset/training_set',\n","    target_size=(64,64),\n","    batch_size=32,\n","    class_mode='binary'\n",")"],"metadata":{"id":"AC9PexXcAXjt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mrCMmGw9pHys"},"source":["### Preprocessing the Test set"]},{"cell_type":"code","source":["test_datagen = ImageDataGenerator(\n","    rescale=1./255\n",")\n","test_set = test_datagen.flow_from_directory(\n","    'dataset/test_set',\n","    target_size=(64,64),\n","    batch_size=32,\n","    class_mode='binary'\n",")"],"metadata":{"id":"46hf57NlDS-J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"af8O4l90gk7B"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"id":"ces1gXY2lmoX"},"source":["### Initialising the CNN"]},{"cell_type":"code","source":["cnn = tf.keras.models.Sequential()"],"metadata":{"id":"QSd3r75jELn8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5YJj_XMl5LF"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64,64,3]))"],"metadata":{"id":"nj1tEO7iEYDn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tf87FpvxmNOJ"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"metadata":{"id":"he_Z0PNPFACz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaTOgD8rm4mU"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"metadata":{"id":"Ib_HoW86FxXr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmiEuvTunKfk"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Flatten())"],"metadata":{"id":"ebI-_6iFF4WO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAoSECOm203v"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"],"metadata":{"id":"RLhygn3oGA2N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTldFvbX28Na"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","source":["cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"],"metadata":{"id":"LvSEOIgLGRvS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6XkI90snSDl"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"id":"vfrFQACEnc6i"},"source":["### Compiling the CNN"]},{"cell_type":"code","source":["cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"D-9BPOMNGe_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehS-v3MIpX2h"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","source":["cnn.fit(x=training_set, validation_data=test_set, epochs=25)"],"metadata":{"id":"1WsaFc-2GyTI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3PZasO0006Z"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"code","source":["test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64,64))\n","# convert to array\n","test_image = image.img_to_array(test_image)\n","# create batches\n","test_image = np.expand_dims(test_image, axis=0)\n","result = cnn.predict(test_image)\n","# 1=dog, 0=cat\n","training_set.class_indices\n","if result[0][0] == 1:\n","  pred = 'dog'\n","else:\n","  pred = 'cat'\n","print(pred)"],"metadata":{"id":"HDZgV10OHH1u"},"execution_count":null,"outputs":[]}]}